# Chapter 2: What's Holding Businesses Back?



Let's be honest—most businesses know they need to transform their data operations. They see competitors pulling ahead, read about AI breakthroughs, and feel the pressure to act. So why aren't they? Adoption has surged, but returns still lag for most organizations. The gap between knowing and doing isn't just wide—it's growing.



Three critical barriers keep emerging.



## The Education Gap

First, there's the education gap. It's not just about technical knowledge—it's about business literacy. When leaders don't understand how data drives value, they either underinvest or chase the wrong outcomes. Only 51.4% of board members consider themselves well-versed in data and AI issues. [SRC-02] That means nearly half the people approving AI budgets don't fully understand what they're buying.



The education tax is real. Leaders who don't understand data make three costly mistakes: they underinvest in the foundation while overinvesting in shiny objects, they rely on vendors without building internal expertise, and they can't distinguish good AI pitches from bad ones. The best teams don't just approve AI projects; they understand how data creates business advantage.



## The Structural Misalignment

Second, structural misalignment cripples potential. Look at most enterprises today: data teams scattered across departments, reporting through IT or finance, fighting for resources and attention. It's like trying to run a restaurant with the kitchen staff split between different buildings. Structure matters.



## The Ownership Vacuum

Third, and most critically, there's no clear owner for data strategy. Without a Chief Data Officer or equivalent leader with real authority, data initiatives become a game of hot potato. Everyone wants the benefits; nobody wants the responsibility.



The CDO tenure data tells a damning story. Over half—53.7%—of CDOs serve less than three years. Nearly a quarter serve less than two. [SRC-03] And 29% of CDOs openly question the long-term future of the position itself. [SRC-04] One MIT Sloan recruiter put it bluntly: there are more data leaders looking for work in the past year than in all previous years combined. [SRC-05]



This is the accountability paradox: everyone wants AI benefits, nobody wants data responsibility. When nobody owns the strategy, everybody owns the failure. United Healthcare learned this the hard way when they deployed an AI claims system without proper governance oversight. The result was a lawsuit and a public relations crisis that could have been prevented by clear ownership and decision rights.



When ownership is clear, the outcome looks very different. JPMorgan Chase’s Contract Intelligence (COiN) program used machine learning to automate contract review and reportedly saved the bank roughly 360,000 hours of manual work each year. [SRC-14] That kind of impact does not happen inside a siloed team. It requires business sponsorship, clear data ownership, and the authority to change how work actually gets done.



These aren't theoretical problems—they're costing real money. But here's what's interesting: these barriers aren't technological. You can buy the best AI platforms, hire top data scientists, and still fail if your foundation isn't right. Consider BP's transformation: before they built their comprehensive data governance framework, they were drowning in inconsistencies. After restructuring their data operations, the technology didn’t change—the approach did.



What made the BP example instructive wasn’t a new tool—it was a new operating discipline. Data definitions stopped being negotiated in hallway conversations and became part of a governed catalog. Field engineers and finance teams stopped debating whose number was “right” and started using shared metrics. The practical result was speed: decisions that once took weeks of reconciliation could be made in days. That is what governance buys you—time, trust, and fewer internal fights over reality.



Let's talk about talent, because this is where many companies stumble hardest. The pattern is predictable: hire expensive data scientists, bury them in IT or finance, watch them leave within 18 months. [SRC-01] Rinse, repeat.



When Vimeo faced this exact cycle, they did something different. They restructured their analytics team entirely. Instead of organizing by stakeholder verticals—product, marketing, operations—they created functional pods focused on core analytics, business insights, and data science. The result was better collaboration, clearer career paths, and people who actually stayed.



The more important move was cultural. Vimeo shifted from “ticket-based analytics” to productized insights. Stakeholders stopped asking for one‑off reports and started using shared metrics that updated automatically. That change sounds small, but it breaks the churn cycle. When analysts see their work used daily, retention improves. When leaders see results without extra headcount, they keep funding the team.



The cost of misalignment isn't just financial. It's existential. While companies debate where to place their data teams, the market moves on. The organizations that pull ahead aren't the ones with better tools. They're the ones whose people can actually use the tools they have.



Education gaps among decision-makers create a particularly vicious cycle. When leaders don't understand data operations, they either underinvest or throw money at vendors without a clear strategy. CSE Insurance broke this cycle by establishing a group of data champions and building data literacy across the entire organization—not just the technical teams.



The frustrating truth? None of this is secret knowledge. The playbook exists. The companies that execute it outperform. The ones that don't keep hiring consultants to tell them what their own data teams already know.



But perhaps the most insidious barrier is the "cost center" mindset. As long as data operations are viewed primarily as an expense, they'll be funded like one. This ignores what Mastercard Advisors proved when they turned transaction data into a consulting business, or what Progressive Insurance demonstrated when driving data became a new revenue stream.



Most businesses try to bolt AI onto existing structures without fixing their data foundation first. That's like dropping a jet engine onto a go-kart chassis. The power is real. The frame isn't built for it.



This is why barrier work has to happen before big model bets. Otherwise, every pilot becomes a cautionary tale.

What does this look like inside a real company? Picture a typical enterprise: data scattered across dozens of systems, managed by different teams, with no single source of truth. They might have talented people, but those people are fighting against their own infrastructure.



GE Aviation faced this exact problem. Their solution was structural, not technical. They created a Self-Service Data team responsible for user enablement, tooling, and data product deployment. More importantly, they separated database administration from data governance—two functions that sound similar but serve entirely different purposes. Clear lines of responsibility changed the output.



That separation matters because it prevents a common failure mode: when the people who keep the systems running are also forced to police quality, both jobs suffer. GE Aviation’s model created accountability without throttling delivery. It also gave business users a consistent interface to data products rather than a rotating cast of spreadsheets. The effect was not just better data. It was faster, more confident decisions made by people who could finally trust what they were looking at.



The regulatory landscape makes these structural problems even more pressing. When BP implemented their governance framework, they didn't just focus on compliance—they built a three-layer approach:

Strategy: Clear ownership and measurable standards

Implementation: Automated monitoring and regular audits

Risk Management: Proactive detection and incident response



The results? Not just better compliance, but faster project delivery and significantly higher data quality scores.



That brings us to the final barrier: measurement.



Most businesses still evaluate data operations using IT metrics—uptime, response time, ticket resolution. These metrics measure whether the lights are on. They don't measure whether anyone is home.



When data products drive growth, it's not because uptime improved. It's because someone asked a different question: what can this data do that we haven't tried yet? The companies getting this right aren't just moving boxes on an org chart. They're rethinking what the boxes are for.



What's striking is how consistent the barriers remain regardless of company size. Whether you're running a $10 million business or a $10 billion enterprise, the fundamental challenges of education gaps, structural misalignment, and unclear ownership persist. The difference lies in how you address them. (We'll cover team sizing and organizational models in Chapter 4.)



So where do we go from here? The path forward isn't about throwing out everything and starting over—it's about systematic transformation. Consider how Progressive Insurance approached this challenge. Instead of trying to rebuild their entire data infrastructure overnight, they started with a single initiative: the Snapshot program. It wasn't just about collecting driving data; it was about proving that data could create new revenue streams while improving core business operations.



These results only come when you address all three critical barriers simultaneously:

1. Education gaps at the leadership level

2. Structural misalignment of data operations

3. Lack of clear ownership and strategy



MGM Resorts International offers a perfect case study here. When they implemented their data-driven decision-making platform in 2019, they didn't just focus on the technology. They restructured their data operations, invested in leadership development, and created clear lines of accountability.

The transition requires patience. But patience is not the same as hesitation. The organizations getting this right don't wait for perfect conditions. They move while the conditions are still imperfect—because that's the only kind of conditions that exist.



The barriers we've laid out in this chapter aren't excuses. They're a diagnosis. And a diagnosis only matters if you act on it.



## The Financial Reality

Let's put real numbers on what these barriers cost.



The headline figure is staggering: poor data quality costs the U.S. economy $3.1 trillion annually. [SRC-06] That's not a projection or an estimate from a vendor white paper—it's the accumulated weight of every bad decision made on bad data, every failed project launched without sufficient preparation, every AI initiative that cratered before it reached production.



The individual failures are just as telling. NASA lost $125 million when a unit mismatch destroyed the Mars Climate Orbiter. [SRC-07] Unity Technologies lost $110 million when poor input data corrupted their Audience Pinpoint algorithms. [SRC-08] These are the failures that make headlines. The ones that don't—the quiet, internal collapses of AI projects that never shipped—are far more common.



The cost of building AI is not trivial, either. Training Meta's LLaMA 2 required over 3 million GPU hours, at roughly $4 million per training run. [SRC-09] A 12-month NLP project costs between $969,000 (using managed services like Amazon SageMaker) and $1.1 million (manual infrastructure). [SRC-10] The human element—specialized talent—represents 30-40% of the total AI budget. [SRC-11]



These numbers matter because they reveal the true cost framework for AI failure:



| Cost Category | What It Looks Like |

|---------------|-------------------|

| **Direct costs** | Wasted technology investment, sunk infrastructure spending |

| **Opportunity costs** | Competitors pulling ahead while you restart |

| **Talent costs** | Data professionals leaving for better-structured organizations (150-200% of salary per departure) |

| **Reputation costs** | Failed AI creates stakeholder distrust—boards, customers, regulators |



When you add these together, the cost of not fixing your foundation dwarfs the cost of building it right.



## The Compounding Effect

These barriers don't add—they multiply. The 95% failure rate isn't the result of any single barrier. [SRC-12] It's the compound result of all three working together.



Consider the multiplication effect:

**Education gap × Structural misalignment** = Wrong priorities funded. Leaders who don't understand data approve the wrong projects, and misaligned structures ensure those projects are executed poorly.

**Structural misalignment × Ownership vacuum** = No one to course-correct. When projects drift, there's no empowered leader to pull them back on track.

**Ownership vacuum × Education gap** = Leaders can't evaluate what they don't understand. Without an owner who can translate data outcomes into business language, the board stays uninformed and the cycle continues.



The GenAI Divide is widening at roughly 15% annually. [SRC-13] That means the gap between AI leaders and laggards isn't linear—it's exponential. Every year you wait, the distance to close gets larger, not smaller.



When leaders lack data literacy, they fund the wrong priorities. When structures are misaligned, resources get trapped in bureaucracy. When no one owns strategy, accountability evaporates. The result is a widening performance gap: organizations with unified data leadership pull farther ahead while fragmented organizations fall behind year after year.



As we move into Part 2, we'll focus on how to remove these barriers systematically. The tools exist. The talent is available. What’s missing is the organizational courage to build the foundation that lets data do its job. In Chapter 3, we move from diagnosis to design—what a modern operating model looks like when you’re ready to execute.



## Sources (Draft)

Format: [SRC-##] Claim. Source. Status. Use `2025_data_sources.md` where applicable; otherwise mark as external.

[SRC-01] Data scientists leave within ~18 months in misaligned orgs. External — verify source.

[SRC-02] Only 51.4% of board members well-versed in data/AI issues. Data & AI Leadership Exchange 2025. External.

[SRC-03] 53.7% of CDOs serve <3 years; 24.1% serve <2 years. Data & AI Leadership Exchange 2025. External.

[SRC-04] 29% of CDOs question long-term future of position. Data & AI Leadership Exchange 2025. External.

[SRC-05] More data leaders looking for work than all previous years combined. MIT Sloan recruiter quote. External — verify source.

[SRC-06] $3.1 trillion annual cost of poor data quality (US). `2025_data_sources.md` (Strategic Report). Verified.

[SRC-07] NASA $125M Mars Climate Orbiter loss. `2025_data_sources.md` (Strategic Report). Verified.

[SRC-08] Unity $110M loss from poor Audience Pinpoint data. `2025_data_sources.md` (Strategic Report). Verified.

[SRC-09] LLaMA 2: 3M GPU hours, ~$4M per training run. `2025_data_sources.md` (Strategic Report). Verified.

[SRC-10] NLP project costs: $969K (SageMaker) vs $1.1M (manual). `2025_data_sources.md` (Strategic Report). Verified.

[SRC-11] Human element: 30-40% of AI budget. `2025_data_sources.md` (Strategic Report). Verified.

[SRC-12] 95% AI failure rate. MIT NANDA 2025. External.

[SRC-13] GenAI Divide widening ~15% annually. MIT NANDA 2025. External — verify specific figure.

[SRC-14] JPMorgan Chase COiN contract intelligence program saving ~360,000 hours annually. Independent / press reporting. External.
